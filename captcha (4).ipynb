{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qbgz_EvxVgGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1a27c7-5a82-4d7b-8882-7e77122739ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Всего у нас  1070 чб изображений, форматы могут как jpg, или img, так и другие. Каждое из них является капчей, состоящей из 5 символов. Названия картинок отображают содержание капчи. Например 2ap5g.jpg. Размеры каждого изображения - 50 на 200 пикселей. Для начала проверим, действительно ли используются все числа и буквы английского алфавита."
      ],
      "metadata": {
        "id": "x0Lwr3Svbvlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir='/content/drive/My Drive/samples/samples'\n",
        "chars = {}\n",
        "for captcha in  os.listdir(dir):\n",
        "  for i in captcha.split(\".\")[0]:\n",
        "    chars[i] = chars.get(i, 0) +1\n",
        "print(len(chars))\n",
        "print(*chars.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXAQnd5-cpkc",
        "outputId": "bc7e3c86-d053-4400-8fd8-c25cb993216b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "d 7 n 3 4 2 w 6 f 5 x p c y m g e b 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видим, что используется всего 19 символов, значит будем тренировать нашу модель всего на 19 символах, что позволит нам существенно улучшить результат. Подготовим наши данные. Будем сопоставлять в y не саму расшифрованную капчу, а матрицу размера 5 (длина любой капчи) на 19 (количество символов). Так у нас для каждой картинки будет матрица, в которой будет по 1 единице в строчке - в столбце, в котором стоит символ"
      ],
      "metadata": {
        "id": "EI9rN214dlbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((1070, 50, 200, 1))  # Добавляем дополнительное измерение для канала\n",
        "y = np.zeros((5, 1070, 19))\n",
        "symbols = list(chars.keys())\n",
        "print(symbols)\n",
        "for i, captcha in enumerate(os.listdir(dir)):\n",
        "    captcha_without_format = captcha.split(\".\")[0]\n",
        "    captcha_image = cv2.imread(os.path.join(dir, captcha), cv2.IMREAD_GRAYSCALE) / 255.0 #нормируем\n",
        "    captcha_image = np.expand_dims(captcha_image, axis=-1)  # Добавляем дополнительное измерение\n",
        "    matr = np.zeros((5, 19))\n",
        "    X[i] = captcha_image\n",
        "    for place, symbol in enumerate(captcha_without_format):\n",
        "        matr[place, list(chars.keys()).index(symbol)] = 1\n",
        "    y[:, i] = matr\n",
        "\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "MpmoV5fHgAG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971ae5a1-7e6d-48af-b9ff-02ffd334fa45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d', '7', 'n', '3', '4', '2', 'w', '6', 'f', '5', 'x', 'p', 'c', 'y', 'm', 'g', 'e', 'b', '8']\n",
            "(1070, 50, 200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделим данные на тренировочные, тестовые и валидационные вручную, потому что мне не охота возиться. Будем использовать следующие пропорции: 0.7 на тренировочные, 0.15 на тестовые и 0.15 на валидационные данные."
      ],
      "metadata": {
        "id": "kZI2ZC2_mcKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = np.arange(X.shape[0])\n",
        "np.random.shuffle(train_indices)\n",
        "X= X[train_indices]\n",
        "y = y[:, train_indices]\n",
        "\n",
        "X_train = X[: 749]\n",
        "y_train = y[:, :749]\n",
        "X_val = X[749 : 910]\n",
        "y_val = y[:, 749 : 910]\n",
        "X_test = X[910:]\n",
        "y_test = y[:, 910:]\n",
        "\n",
        "y_train = np.transpose(y_train, (1, 0, 2))\n",
        "y_test = np.transpose(y_test, (1, 0, 2))\n",
        "y_val = np.transpose(y_val, (1, 0, 2))\n",
        "\n",
        "# Проверка формы разделенных данных\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_val shape:\", y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F4Xhw6Hmi_k",
        "outputId": "bfd075cb-7e2c-4b1e-ff16-ca9532a8885a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (749, 50, 200, 1)\n",
            "y_train shape: (749, 5, 19)\n",
            "X_test shape: (160, 50, 200, 1)\n",
            "y_test shape: (160, 5, 19)\n",
            "X_val shape: (161, 50, 200, 1)\n",
            "y_val shape: (161, 5, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я собираюсь использовать сверточную нейронную сеть для решения задачи, ведь они как раз подходят для работы с изображениями."
      ],
      "metadata": {
        "id": "ddcZgqTFqBsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input\n",
        "from keras.layers import Reshape\n",
        "import keras"
      ],
      "metadata": {
        "id": "hKRe1QqbvdG7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_4():\n",
        "    # Входной слой\n",
        "    inp_layer = Input(shape=(50, 200, 1))  # Входные данные имеют форму (50, 200, 1)\n",
        "\n",
        "    # Первый сверточный слой\n",
        "    convol_layer_1 = Conv2D(32, (3, 3), padding='same', activation='relu')(inp_layer)  # 32 фильтра размером 3x3\n",
        "    pool_1 = MaxPooling2D((2, 2), padding='same')(convol_layer_1)\n",
        "\n",
        "    # Второй сверточный слой\n",
        "    convol_layer_2 = Conv2D(64, (3, 3), padding='same', activation='relu')(pool_1)\n",
        "    pool_2 = MaxPooling2D((2, 2), padding='same')(convol_layer_2)\n",
        "\n",
        "    # третий сверточный слой\n",
        "    convol_layer_3 = Conv2D(128, (3, 3), padding='same', activation='relu')(pool_2)\n",
        "    pool_3 = MaxPooling2D((2, 2), padding='same')(convol_layer_3)\n",
        "\n",
        "    fl = Flatten()(pool_3)\n",
        "    x = Dropout(0.4)(fl)\n",
        "    # пытаемся предотвратить переобучение\n",
        "    x = BatchNormalization()(x)\n",
        "    outputs = []\n",
        "\n",
        "\n",
        "    # для каждой отдельной буквы создаем отдельную как бы ветку, чтобы можно было угадывать ее отдельно\n",
        "    dense1 = Dense(64 , activation='relu')(x)\n",
        "    dropout1= Dropout(0.5)(dense1)\n",
        "    dpo1 = BatchNormalization()(dropout1)\n",
        "    output1 = Dense(19 , activation='softmax')(dpo1)\n",
        "    outputs.append(output1)\n",
        "\n",
        "    dense2 = Dense(64 , activation='relu')(x)\n",
        "    dropout2= Dropout(0.5)(dense2)\n",
        "    dpo2 = BatchNormalization()(dropout2)\n",
        "    output2 = Dense(19 , activation='softmax')(dpo2)\n",
        "    outputs.append(output2)\n",
        "\n",
        "    dense3 = Dense(64 , activation='relu')(x)\n",
        "    dropout3= Dropout(0.5)(dense3)\n",
        "    dpo3 = BatchNormalization()(dropout3)\n",
        "    output3 = Dense(19 , activation='softmax')(dpo3)\n",
        "    outputs.append(output3)\n",
        "\n",
        "    dense4 = Dense(64 , activation='relu')(x)\n",
        "    dropout4= Dropout(0.5)(dense4)\n",
        "    dpo4 = BatchNormalization()(dropout4)\n",
        "    output4 = Dense(19 , activation='softmax')(dpo4)\n",
        "    outputs.append(output4)\n",
        "\n",
        "    dense5 = Dense(64 , activation='relu')(x)\n",
        "    dropout5= Dropout(0.5)(dense5)\n",
        "    dpo5 = BatchNormalization()(dropout5)\n",
        "    output5 = Dense(19 , activation='softmax')(dpo5)\n",
        "    outputs.append(output5)\n",
        "\n",
        "    model = Model(inputs=inp_layer, outputs=outputs)\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"] * 5)\n",
        "\n",
        "    return model\n",
        "\n",
        "model_4 = build_model_4()\n",
        "model_4.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "NhoWb8W-e9g6",
        "outputId": "caad959f-9b31-49e5-ccaf-090f944e9ad2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │            \u001b[38;5;34m320\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │         \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22400\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22400\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22400\u001b[0m)          │         \u001b[38;5;34m89,600\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │      \u001b[38;5;34m1,433,664\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │      \u001b[38;5;34m1,433,664\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │      \u001b[38;5;34m1,433,664\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │      \u001b[38;5;34m1,433,664\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │      \u001b[38;5;34m1,433,664\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m256\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m256\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m256\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m256\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │          \u001b[38;5;34m1,235\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │          \u001b[38;5;34m1,235\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │          \u001b[38;5;34m1,235\u001b[0m │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │          \u001b[38;5;34m1,235\u001b[0m │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │          \u001b[38;5;34m1,235\u001b[0m │ batch_normalization_5… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22400</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22400</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22400</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">89,600</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,433,664</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,433,664</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,433,664</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,433,664</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,433,664</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │ batch_normalization_5… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,358,047\u001b[0m (28.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,358,047</span> (28.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,312,607\u001b[0m (27.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,312,607</span> (27.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m45,440\u001b[0m (177.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,440</span> (177.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Метрика для мониторинга\n",
        "    patience=10,         # Количество эпох без улучшения, после которых остановить обучение\n",
        "    restore_best_weights=True  # Восстановить лучшие веса после окончания обучения\n",
        ")\n",
        "\n",
        "\n",
        "history = model_4.fit(\n",
        "    X_train, [y_train[:, i] for i in range(5)],\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    validation_data=(X_val, [y_val[:, i] for i in range(5)]),\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U89KJsaefvmP",
        "outputId": "a46c940c-b46d-423b-9266-175ea3b64f1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 516ms/step - dense_1_accuracy: 0.0692 - dense_3_accuracy: 0.0756 - dense_5_accuracy: 0.0546 - dense_7_accuracy: 0.0735 - dense_9_accuracy: 0.0379 - loss: 17.4217 - val_dense_1_accuracy: 0.1801 - val_dense_3_accuracy: 0.1739 - val_dense_5_accuracy: 0.1242 - val_dense_7_accuracy: 0.0559 - val_dense_9_accuracy: 0.0807 - val_loss: 14.6057\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - dense_1_accuracy: 0.2402 - dense_3_accuracy: 0.1912 - dense_5_accuracy: 0.1445 - dense_7_accuracy: 0.1418 - dense_9_accuracy: 0.1291 - loss: 14.1617 - val_dense_1_accuracy: 0.3602 - val_dense_3_accuracy: 0.1988 - val_dense_5_accuracy: 0.0621 - val_dense_7_accuracy: 0.2236 - val_dense_9_accuracy: 0.1242 - val_loss: 14.2831\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - dense_1_accuracy: 0.5138 - dense_3_accuracy: 0.4405 - dense_5_accuracy: 0.3811 - dense_7_accuracy: 0.3763 - dense_9_accuracy: 0.3247 - loss: 10.1210 - val_dense_1_accuracy: 0.4099 - val_dense_3_accuracy: 0.3230 - val_dense_5_accuracy: 0.2609 - val_dense_7_accuracy: 0.1988 - val_dense_9_accuracy: 0.1366 - val_loss: 13.9903\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - dense_1_accuracy: 0.7700 - dense_3_accuracy: 0.6004 - dense_5_accuracy: 0.5215 - dense_7_accuracy: 0.5307 - dense_9_accuracy: 0.5692 - loss: 7.4537 - val_dense_1_accuracy: 0.5093 - val_dense_3_accuracy: 0.4037 - val_dense_5_accuracy: 0.2857 - val_dense_7_accuracy: 0.1801 - val_dense_9_accuracy: 0.1491 - val_loss: 13.7703\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.8545 - dense_3_accuracy: 0.7933 - dense_5_accuracy: 0.6728 - dense_7_accuracy: 0.6339 - dense_9_accuracy: 0.6480 - loss: 5.7876 - val_dense_1_accuracy: 0.5590 - val_dense_3_accuracy: 0.5404 - val_dense_5_accuracy: 0.2733 - val_dense_7_accuracy: 0.1863 - val_dense_9_accuracy: 0.1180 - val_loss: 13.4933\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - dense_1_accuracy: 0.9039 - dense_3_accuracy: 0.8466 - dense_5_accuracy: 0.7531 - dense_7_accuracy: 0.7238 - dense_9_accuracy: 0.7060 - loss: 4.9090 - val_dense_1_accuracy: 0.5342 - val_dense_3_accuracy: 0.5466 - val_dense_5_accuracy: 0.3727 - val_dense_7_accuracy: 0.2484 - val_dense_9_accuracy: 0.0932 - val_loss: 13.2460\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9221 - dense_3_accuracy: 0.9081 - dense_5_accuracy: 0.8038 - dense_7_accuracy: 0.7709 - dense_9_accuracy: 0.8189 - loss: 4.1986 - val_dense_1_accuracy: 0.6708 - val_dense_3_accuracy: 0.6149 - val_dense_5_accuracy: 0.4224 - val_dense_7_accuracy: 0.2298 - val_dense_9_accuracy: 0.0994 - val_loss: 12.9952\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - dense_1_accuracy: 0.9482 - dense_3_accuracy: 0.9229 - dense_5_accuracy: 0.8644 - dense_7_accuracy: 0.8376 - dense_9_accuracy: 0.8552 - loss: 3.5769 - val_dense_1_accuracy: 0.7516 - val_dense_3_accuracy: 0.7391 - val_dense_5_accuracy: 0.5031 - val_dense_7_accuracy: 0.3416 - val_dense_9_accuracy: 0.1553 - val_loss: 12.6172\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - dense_1_accuracy: 0.9627 - dense_3_accuracy: 0.9547 - dense_5_accuracy: 0.8974 - dense_7_accuracy: 0.8527 - dense_9_accuracy: 0.8791 - loss: 3.1648 - val_dense_1_accuracy: 0.8012 - val_dense_3_accuracy: 0.7205 - val_dense_5_accuracy: 0.5093 - val_dense_7_accuracy: 0.3789 - val_dense_9_accuracy: 0.2112 - val_loss: 12.2697\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9754 - dense_3_accuracy: 0.9424 - dense_5_accuracy: 0.9428 - dense_7_accuracy: 0.8847 - dense_9_accuracy: 0.8969 - loss: 2.7806 - val_dense_1_accuracy: 0.9068 - val_dense_3_accuracy: 0.8261 - val_dense_5_accuracy: 0.5280 - val_dense_7_accuracy: 0.4596 - val_dense_9_accuracy: 0.2671 - val_loss: 11.6018\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - dense_1_accuracy: 0.9704 - dense_3_accuracy: 0.9696 - dense_5_accuracy: 0.9315 - dense_7_accuracy: 0.8879 - dense_9_accuracy: 0.9373 - loss: 2.5130 - val_dense_1_accuracy: 0.8944 - val_dense_3_accuracy: 0.8447 - val_dense_5_accuracy: 0.5652 - val_dense_7_accuracy: 0.4720 - val_dense_9_accuracy: 0.2733 - val_loss: 11.3614\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - dense_1_accuracy: 0.9764 - dense_3_accuracy: 0.9642 - dense_5_accuracy: 0.9622 - dense_7_accuracy: 0.9312 - dense_9_accuracy: 0.9528 - loss: 2.2350 - val_dense_1_accuracy: 0.9255 - val_dense_3_accuracy: 0.8944 - val_dense_5_accuracy: 0.6211 - val_dense_7_accuracy: 0.5776 - val_dense_9_accuracy: 0.3602 - val_loss: 10.7290\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - dense_1_accuracy: 0.9869 - dense_3_accuracy: 0.9656 - dense_5_accuracy: 0.9665 - dense_7_accuracy: 0.9303 - dense_9_accuracy: 0.9519 - loss: 2.1157 - val_dense_1_accuracy: 0.9627 - val_dense_3_accuracy: 0.9130 - val_dense_5_accuracy: 0.6460 - val_dense_7_accuracy: 0.5901 - val_dense_9_accuracy: 0.3665 - val_loss: 10.2649\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9875 - dense_3_accuracy: 0.9844 - dense_5_accuracy: 0.9580 - dense_7_accuracy: 0.9352 - dense_9_accuracy: 0.9491 - loss: 1.8945 - val_dense_1_accuracy: 0.9814 - val_dense_3_accuracy: 0.9255 - val_dense_5_accuracy: 0.6832 - val_dense_7_accuracy: 0.5839 - val_dense_9_accuracy: 0.4720 - val_loss: 9.6065\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9948 - dense_3_accuracy: 0.9792 - dense_5_accuracy: 0.9590 - dense_7_accuracy: 0.9509 - dense_9_accuracy: 0.9586 - loss: 1.7973 - val_dense_1_accuracy: 0.9876 - val_dense_3_accuracy: 0.9255 - val_dense_5_accuracy: 0.7081 - val_dense_7_accuracy: 0.6584 - val_dense_9_accuracy: 0.4845 - val_loss: 9.0548\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9923 - dense_3_accuracy: 0.9754 - dense_5_accuracy: 0.9670 - dense_7_accuracy: 0.9596 - dense_9_accuracy: 0.9740 - loss: 1.6563 - val_dense_1_accuracy: 0.9876 - val_dense_3_accuracy: 0.9379 - val_dense_5_accuracy: 0.7391 - val_dense_7_accuracy: 0.7267 - val_dense_9_accuracy: 0.5652 - val_loss: 8.4304\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9926 - dense_3_accuracy: 0.9829 - dense_5_accuracy: 0.9704 - dense_7_accuracy: 0.9789 - dense_9_accuracy: 0.9715 - loss: 1.4806 - val_dense_1_accuracy: 0.9938 - val_dense_3_accuracy: 0.9441 - val_dense_5_accuracy: 0.7578 - val_dense_7_accuracy: 0.7702 - val_dense_9_accuracy: 0.6460 - val_loss: 7.7906\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9872 - dense_3_accuracy: 0.9831 - dense_5_accuracy: 0.9755 - dense_7_accuracy: 0.9619 - dense_9_accuracy: 0.9741 - loss: 1.4670 - val_dense_1_accuracy: 0.9876 - val_dense_3_accuracy: 0.9503 - val_dense_5_accuracy: 0.8137 - val_dense_7_accuracy: 0.7578 - val_dense_9_accuracy: 0.6957 - val_loss: 7.2823\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - dense_1_accuracy: 0.9927 - dense_3_accuracy: 0.9870 - dense_5_accuracy: 0.9734 - dense_7_accuracy: 0.9661 - dense_9_accuracy: 0.9796 - loss: 1.3922 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9503 - val_dense_5_accuracy: 0.8261 - val_dense_7_accuracy: 0.7950 - val_dense_9_accuracy: 0.7143 - val_loss: 6.4123\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9928 - dense_3_accuracy: 0.9972 - dense_5_accuracy: 0.9931 - dense_7_accuracy: 0.9747 - dense_9_accuracy: 0.9720 - loss: 1.2730 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9503 - val_dense_5_accuracy: 0.8509 - val_dense_7_accuracy: 0.8137 - val_dense_9_accuracy: 0.7267 - val_loss: 5.7446\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - dense_1_accuracy: 0.9925 - dense_3_accuracy: 0.9833 - dense_5_accuracy: 0.9802 - dense_7_accuracy: 0.9708 - dense_9_accuracy: 0.9852 - loss: 1.2038 - val_dense_1_accuracy: 0.9938 - val_dense_3_accuracy: 0.9565 - val_dense_5_accuracy: 0.8634 - val_dense_7_accuracy: 0.8261 - val_dense_9_accuracy: 0.7516 - val_loss: 4.9946\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - dense_1_accuracy: 0.9897 - dense_3_accuracy: 0.9883 - dense_5_accuracy: 0.9849 - dense_7_accuracy: 0.9826 - dense_9_accuracy: 0.9810 - loss: 1.1378 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9503 - val_dense_5_accuracy: 0.8696 - val_dense_7_accuracy: 0.8385 - val_dense_9_accuracy: 0.7453 - val_loss: 4.5749\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - dense_1_accuracy: 0.9908 - dense_3_accuracy: 0.9930 - dense_5_accuracy: 0.9835 - dense_7_accuracy: 0.9866 - dense_9_accuracy: 0.9776 - loss: 1.0749 - val_dense_1_accuracy: 0.9938 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.8820 - val_dense_7_accuracy: 0.8385 - val_dense_9_accuracy: 0.7640 - val_loss: 4.2082\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - dense_1_accuracy: 0.9945 - dense_3_accuracy: 0.9940 - dense_5_accuracy: 0.9765 - dense_7_accuracy: 0.9855 - dense_9_accuracy: 0.9827 - loss: 1.0570 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.8944 - val_dense_7_accuracy: 0.8509 - val_dense_9_accuracy: 0.7826 - val_loss: 3.7034\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - dense_1_accuracy: 0.9925 - dense_3_accuracy: 0.9946 - dense_5_accuracy: 0.9846 - dense_7_accuracy: 0.9791 - dense_9_accuracy: 0.9714 - loss: 1.0051 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.8882 - val_dense_7_accuracy: 0.8571 - val_dense_9_accuracy: 0.7826 - val_loss: 3.2502\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - dense_1_accuracy: 0.9921 - dense_3_accuracy: 0.9921 - dense_5_accuracy: 0.9864 - dense_7_accuracy: 0.9776 - dense_9_accuracy: 0.9925 - loss: 0.9538 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8323 - val_dense_9_accuracy: 0.7826 - val_loss: 2.9934\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - dense_1_accuracy: 0.9896 - dense_3_accuracy: 0.9904 - dense_5_accuracy: 0.9919 - dense_7_accuracy: 0.9826 - dense_9_accuracy: 0.9791 - loss: 0.9300 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9565 - val_dense_5_accuracy: 0.8944 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.7950 - val_loss: 2.7913\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - dense_1_accuracy: 0.9921 - dense_3_accuracy: 0.9848 - dense_5_accuracy: 0.9874 - dense_7_accuracy: 0.9871 - dense_9_accuracy: 0.9842 - loss: 0.8343 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9565 - val_dense_5_accuracy: 0.9006 - val_dense_7_accuracy: 0.8509 - val_dense_9_accuracy: 0.8012 - val_loss: 2.5940\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9976 - dense_3_accuracy: 0.9882 - dense_5_accuracy: 0.9894 - dense_7_accuracy: 0.9834 - dense_9_accuracy: 0.9881 - loss: 0.8089 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.7950 - val_loss: 2.5217\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9981 - dense_3_accuracy: 0.9988 - dense_5_accuracy: 0.9977 - dense_7_accuracy: 0.9896 - dense_9_accuracy: 0.9885 - loss: 0.7887 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8509 - val_dense_9_accuracy: 0.8075 - val_loss: 2.0637\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9963 - dense_3_accuracy: 0.9944 - dense_5_accuracy: 0.9876 - dense_7_accuracy: 0.9851 - dense_9_accuracy: 0.9784 - loss: 0.7485 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8634 - val_dense_9_accuracy: 0.8012 - val_loss: 2.0199\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9971 - dense_3_accuracy: 0.9864 - dense_5_accuracy: 0.9917 - dense_7_accuracy: 0.9825 - dense_9_accuracy: 0.9843 - loss: 0.7873 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9814 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8571 - val_dense_9_accuracy: 0.8137 - val_loss: 1.9206\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - dense_1_accuracy: 0.9944 - dense_3_accuracy: 0.9948 - dense_5_accuracy: 0.9935 - dense_7_accuracy: 0.9952 - dense_9_accuracy: 0.9921 - loss: 0.6867 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.9006 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8385 - val_loss: 1.9520\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9976 - dense_3_accuracy: 0.9977 - dense_5_accuracy: 0.9914 - dense_7_accuracy: 0.9895 - dense_9_accuracy: 0.9934 - loss: 0.6699 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.8075 - val_loss: 1.8512\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - dense_1_accuracy: 1.0000 - dense_3_accuracy: 0.9963 - dense_5_accuracy: 0.9870 - dense_7_accuracy: 0.9822 - dense_9_accuracy: 0.9820 - loss: 0.6740 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8199 - val_loss: 1.7613\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - dense_1_accuracy: 0.9975 - dense_3_accuracy: 0.9879 - dense_5_accuracy: 0.9939 - dense_7_accuracy: 0.9893 - dense_9_accuracy: 0.9936 - loss: 0.6128 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.8137 - val_loss: 1.7861\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - dense_1_accuracy: 0.9987 - dense_3_accuracy: 0.9957 - dense_5_accuracy: 0.9942 - dense_7_accuracy: 0.9930 - dense_9_accuracy: 0.9867 - loss: 0.5776 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.8882 - val_dense_7_accuracy: 0.8571 - val_dense_9_accuracy: 0.8323 - val_loss: 1.6620\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - dense_1_accuracy: 0.9970 - dense_3_accuracy: 0.9889 - dense_5_accuracy: 0.9946 - dense_7_accuracy: 0.9949 - dense_9_accuracy: 0.9938 - loss: 0.5821 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.8944 - val_dense_7_accuracy: 0.8571 - val_dense_9_accuracy: 0.8199 - val_loss: 1.7899\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - dense_1_accuracy: 0.9985 - dense_3_accuracy: 0.9990 - dense_5_accuracy: 0.9969 - dense_7_accuracy: 0.9889 - dense_9_accuracy: 0.9917 - loss: 0.5705 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9565 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.8261 - val_loss: 1.6453\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - dense_1_accuracy: 0.9979 - dense_3_accuracy: 0.9975 - dense_5_accuracy: 0.9910 - dense_7_accuracy: 0.9940 - dense_9_accuracy: 0.9936 - loss: 0.5609 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9006 - val_dense_7_accuracy: 0.8634 - val_dense_9_accuracy: 0.8137 - val_loss: 1.7362\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - dense_1_accuracy: 0.9921 - dense_3_accuracy: 0.9972 - dense_5_accuracy: 0.9922 - dense_7_accuracy: 0.9845 - dense_9_accuracy: 0.9863 - loss: 0.5515 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9006 - val_dense_7_accuracy: 0.8634 - val_dense_9_accuracy: 0.8261 - val_loss: 1.6694\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - dense_1_accuracy: 0.9959 - dense_3_accuracy: 0.9989 - dense_5_accuracy: 0.9946 - dense_7_accuracy: 0.9937 - dense_9_accuracy: 0.9935 - loss: 0.5274 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8634 - val_dense_9_accuracy: 0.8323 - val_loss: 1.6659\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9985 - dense_3_accuracy: 0.9997 - dense_5_accuracy: 0.9923 - dense_7_accuracy: 0.9979 - dense_9_accuracy: 0.9935 - loss: 0.4972 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8571 - val_dense_9_accuracy: 0.8199 - val_loss: 1.6095\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - dense_1_accuracy: 0.9963 - dense_3_accuracy: 1.0000 - dense_5_accuracy: 0.9960 - dense_7_accuracy: 0.9902 - dense_9_accuracy: 0.9849 - loss: 0.4943 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.8944 - val_dense_7_accuracy: 0.8509 - val_dense_9_accuracy: 0.8447 - val_loss: 1.6065\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9981 - dense_3_accuracy: 0.9951 - dense_5_accuracy: 0.9895 - dense_7_accuracy: 0.9917 - dense_9_accuracy: 0.9957 - loss: 0.4795 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8571 - val_dense_9_accuracy: 0.8261 - val_loss: 1.5345\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - dense_1_accuracy: 0.9957 - dense_3_accuracy: 0.9958 - dense_5_accuracy: 0.9944 - dense_7_accuracy: 0.9919 - dense_9_accuracy: 0.9889 - loss: 0.4683 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.8385 - val_loss: 1.5086\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - dense_1_accuracy: 0.9886 - dense_3_accuracy: 0.9956 - dense_5_accuracy: 0.9990 - dense_7_accuracy: 0.9939 - dense_9_accuracy: 0.9951 - loss: 0.4581 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9006 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.8447 - val_loss: 1.5382\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9941 - dense_3_accuracy: 0.9959 - dense_5_accuracy: 0.9968 - dense_7_accuracy: 0.9955 - dense_9_accuracy: 0.9981 - loss: 0.4312 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8571 - val_dense_9_accuracy: 0.8509 - val_loss: 1.5411\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - dense_1_accuracy: 0.9939 - dense_3_accuracy: 0.9959 - dense_5_accuracy: 0.9900 - dense_7_accuracy: 0.9811 - dense_9_accuracy: 0.9976 - loss: 0.4591 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9565 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8447 - val_dense_9_accuracy: 0.8385 - val_loss: 1.6074\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - dense_1_accuracy: 0.9908 - dense_3_accuracy: 0.9981 - dense_5_accuracy: 0.9966 - dense_7_accuracy: 0.9798 - dense_9_accuracy: 0.9986 - loss: 0.4314 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.8944 - val_dense_7_accuracy: 0.8634 - val_dense_9_accuracy: 0.8323 - val_loss: 1.5747\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - dense_1_accuracy: 0.9971 - dense_3_accuracy: 0.9971 - dense_5_accuracy: 0.9895 - dense_7_accuracy: 0.9941 - dense_9_accuracy: 0.9821 - loss: 0.4129 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8447 - val_loss: 1.4740\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - dense_1_accuracy: 0.9935 - dense_3_accuracy: 0.9983 - dense_5_accuracy: 0.9914 - dense_7_accuracy: 0.9911 - dense_9_accuracy: 0.9962 - loss: 0.4215 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8571 - val_dense_9_accuracy: 0.8385 - val_loss: 1.4821\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - dense_1_accuracy: 0.9887 - dense_3_accuracy: 0.9993 - dense_5_accuracy: 0.9963 - dense_7_accuracy: 0.9891 - dense_9_accuracy: 0.9939 - loss: 0.4288 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8509 - val_loss: 1.4913\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - dense_1_accuracy: 0.9981 - dense_3_accuracy: 0.9958 - dense_5_accuracy: 0.9894 - dense_7_accuracy: 0.9973 - dense_9_accuracy: 0.9901 - loss: 0.3914 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9255 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.8385 - val_loss: 1.5061\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9978 - dense_3_accuracy: 0.9906 - dense_5_accuracy: 0.9929 - dense_7_accuracy: 0.9965 - dense_9_accuracy: 0.9903 - loss: 0.3488 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9255 - val_dense_7_accuracy: 0.8509 - val_dense_9_accuracy: 0.8199 - val_loss: 1.5258\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - dense_1_accuracy: 0.9993 - dense_3_accuracy: 0.9961 - dense_5_accuracy: 0.9973 - dense_7_accuracy: 0.9988 - dense_9_accuracy: 0.9937 - loss: 0.3605 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9255 - val_dense_7_accuracy: 0.8571 - val_dense_9_accuracy: 0.8509 - val_loss: 1.4716\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9997 - dense_3_accuracy: 0.9970 - dense_5_accuracy: 0.9901 - dense_7_accuracy: 0.9968 - dense_9_accuracy: 0.9940 - loss: 0.3684 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9814 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8447 - val_loss: 1.4566\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9997 - dense_3_accuracy: 0.9985 - dense_5_accuracy: 0.9996 - dense_7_accuracy: 0.9921 - dense_9_accuracy: 0.9955 - loss: 0.3435 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8323 - val_loss: 1.4776\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9939 - dense_3_accuracy: 0.9982 - dense_5_accuracy: 0.9968 - dense_7_accuracy: 0.9908 - dense_9_accuracy: 0.9882 - loss: 0.3915 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9814 - val_dense_5_accuracy: 0.9193 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8447 - val_loss: 1.4260\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - dense_1_accuracy: 0.9997 - dense_3_accuracy: 0.9870 - dense_5_accuracy: 0.9938 - dense_7_accuracy: 0.9962 - dense_9_accuracy: 0.9823 - loss: 0.3634 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9255 - val_dense_7_accuracy: 0.8820 - val_dense_9_accuracy: 0.8447 - val_loss: 1.4874\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9957 - dense_3_accuracy: 1.0000 - dense_5_accuracy: 0.9960 - dense_7_accuracy: 0.9926 - dense_9_accuracy: 0.9885 - loss: 0.3600 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9255 - val_dense_7_accuracy: 0.8882 - val_dense_9_accuracy: 0.8323 - val_loss: 1.4535\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9994 - dense_3_accuracy: 0.9945 - dense_5_accuracy: 0.9952 - dense_7_accuracy: 0.9938 - dense_9_accuracy: 0.9959 - loss: 0.3396 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9317 - val_dense_7_accuracy: 0.8882 - val_dense_9_accuracy: 0.8447 - val_loss: 1.4491\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - dense_1_accuracy: 0.9988 - dense_3_accuracy: 0.9882 - dense_5_accuracy: 0.9968 - dense_7_accuracy: 0.9926 - dense_9_accuracy: 0.9887 - loss: 0.3676 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.9193 - val_dense_7_accuracy: 0.8882 - val_dense_9_accuracy: 0.8634 - val_loss: 1.4966\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9952 - dense_3_accuracy: 0.9966 - dense_5_accuracy: 0.9904 - dense_7_accuracy: 0.9810 - dense_9_accuracy: 0.9913 - loss: 0.3614 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.9317 - val_dense_7_accuracy: 0.8820 - val_dense_9_accuracy: 0.8571 - val_loss: 1.4243\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - dense_1_accuracy: 0.9953 - dense_3_accuracy: 0.9972 - dense_5_accuracy: 0.9951 - dense_7_accuracy: 0.9948 - dense_9_accuracy: 0.9936 - loss: 0.3254 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9255 - val_dense_7_accuracy: 0.8820 - val_dense_9_accuracy: 0.8571 - val_loss: 1.3579\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - dense_1_accuracy: 0.9945 - dense_3_accuracy: 1.0000 - dense_5_accuracy: 0.9942 - dense_7_accuracy: 0.9981 - dense_9_accuracy: 0.9994 - loss: 0.2865 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9255 - val_dense_7_accuracy: 0.8882 - val_dense_9_accuracy: 0.8696 - val_loss: 1.4056\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - dense_1_accuracy: 0.9970 - dense_3_accuracy: 0.9979 - dense_5_accuracy: 0.9972 - dense_7_accuracy: 0.9925 - dense_9_accuracy: 1.0000 - loss: 0.2836 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9317 - val_dense_7_accuracy: 0.9068 - val_dense_9_accuracy: 0.8385 - val_loss: 1.4124\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9946 - dense_3_accuracy: 0.9974 - dense_5_accuracy: 0.9973 - dense_7_accuracy: 0.9969 - dense_9_accuracy: 0.9924 - loss: 0.2828 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9193 - val_dense_7_accuracy: 0.9006 - val_dense_9_accuracy: 0.8571 - val_loss: 1.3785\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9961 - dense_3_accuracy: 0.9971 - dense_5_accuracy: 0.9949 - dense_7_accuracy: 0.9980 - dense_9_accuracy: 0.9948 - loss: 0.2902 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9814 - val_dense_5_accuracy: 0.9193 - val_dense_7_accuracy: 0.8882 - val_dense_9_accuracy: 0.8509 - val_loss: 1.4114\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - dense_1_accuracy: 0.9955 - dense_3_accuracy: 0.9993 - dense_5_accuracy: 0.9889 - dense_7_accuracy: 0.9964 - dense_9_accuracy: 0.9977 - loss: 0.2664 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9814 - val_dense_5_accuracy: 0.9317 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8571 - val_loss: 1.3726\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - dense_1_accuracy: 0.9990 - dense_3_accuracy: 0.9966 - dense_5_accuracy: 0.9986 - dense_7_accuracy: 0.9977 - dense_9_accuracy: 0.9960 - loss: 0.2514 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9814 - val_dense_5_accuracy: 0.9317 - val_dense_7_accuracy: 0.8820 - val_dense_9_accuracy: 0.8509 - val_loss: 1.4218\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - dense_1_accuracy: 0.9990 - dense_3_accuracy: 1.0000 - dense_5_accuracy: 0.9981 - dense_7_accuracy: 0.9996 - dense_9_accuracy: 0.9899 - loss: 0.2679 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9379 - val_dense_7_accuracy: 0.8634 - val_dense_9_accuracy: 0.8447 - val_loss: 1.4519\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - dense_1_accuracy: 0.9977 - dense_3_accuracy: 0.9948 - dense_5_accuracy: 0.9953 - dense_7_accuracy: 0.9935 - dense_9_accuracy: 0.9922 - loss: 0.2792 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9379 - val_dense_7_accuracy: 0.8820 - val_dense_9_accuracy: 0.8571 - val_loss: 1.3708\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - dense_1_accuracy: 0.9855 - dense_3_accuracy: 0.9995 - dense_5_accuracy: 0.9955 - dense_7_accuracy: 0.9952 - dense_9_accuracy: 0.9900 - loss: 0.2858 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9379 - val_dense_7_accuracy: 0.8882 - val_dense_9_accuracy: 0.8571 - val_loss: 1.3755\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - dense_1_accuracy: 0.9912 - dense_3_accuracy: 0.9955 - dense_5_accuracy: 0.9989 - dense_7_accuracy: 0.9953 - dense_9_accuracy: 0.9869 - loss: 0.2585 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9814 - val_dense_5_accuracy: 0.9503 - val_dense_7_accuracy: 0.8882 - val_dense_9_accuracy: 0.8509 - val_loss: 1.3291\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - dense_1_accuracy: 0.9951 - dense_3_accuracy: 0.9960 - dense_5_accuracy: 0.9982 - dense_7_accuracy: 0.9971 - dense_9_accuracy: 0.9996 - loss: 0.2504 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9255 - val_dense_7_accuracy: 0.8820 - val_dense_9_accuracy: 0.8571 - val_loss: 1.3738\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - dense_1_accuracy: 0.9999 - dense_3_accuracy: 0.9961 - dense_5_accuracy: 0.9942 - dense_7_accuracy: 0.9964 - dense_9_accuracy: 0.9812 - loss: 0.2516 - val_dense_1_accuracy: 0.9938 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9379 - val_dense_7_accuracy: 0.8820 - val_dense_9_accuracy: 0.8758 - val_loss: 1.3087\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - dense_1_accuracy: 1.0000 - dense_3_accuracy: 0.9978 - dense_5_accuracy: 0.9891 - dense_7_accuracy: 0.9926 - dense_9_accuracy: 0.9840 - loss: 0.2661 - val_dense_1_accuracy: 0.9938 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9317 - val_dense_7_accuracy: 0.8944 - val_dense_9_accuracy: 0.8509 - val_loss: 1.3265\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9972 - dense_3_accuracy: 0.9985 - dense_5_accuracy: 0.9986 - dense_7_accuracy: 0.9917 - dense_9_accuracy: 0.9978 - loss: 0.2543 - val_dense_1_accuracy: 0.9938 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8509 - val_loss: 1.3284\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - dense_1_accuracy: 0.9974 - dense_3_accuracy: 0.9999 - dense_5_accuracy: 0.9966 - dense_7_accuracy: 0.9952 - dense_9_accuracy: 0.9992 - loss: 0.2172 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.8509 - val_loss: 1.3768\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9938 - dense_3_accuracy: 0.9991 - dense_5_accuracy: 1.0000 - dense_7_accuracy: 0.9958 - dense_9_accuracy: 0.9921 - loss: 0.2346 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9255 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8509 - val_loss: 1.3403\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - dense_1_accuracy: 0.9946 - dense_3_accuracy: 0.9993 - dense_5_accuracy: 0.9946 - dense_7_accuracy: 0.9914 - dense_9_accuracy: 0.9938 - loss: 0.3082 - val_dense_1_accuracy: 0.9938 - val_dense_3_accuracy: 0.9752 - val_dense_5_accuracy: 0.8882 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8447 - val_loss: 1.4831\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - dense_1_accuracy: 0.9935 - dense_3_accuracy: 0.9932 - dense_5_accuracy: 0.9928 - dense_7_accuracy: 0.9901 - dense_9_accuracy: 0.9837 - loss: 0.3373 - val_dense_1_accuracy: 0.9938 - val_dense_3_accuracy: 0.9627 - val_dense_5_accuracy: 0.9068 - val_dense_7_accuracy: 0.8634 - val_dense_9_accuracy: 0.8261 - val_loss: 1.6126\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - dense_1_accuracy: 0.9891 - dense_3_accuracy: 0.9959 - dense_5_accuracy: 0.9976 - dense_7_accuracy: 0.9900 - dense_9_accuracy: 0.9923 - loss: 0.3236 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8447 - val_loss: 1.4061\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - dense_1_accuracy: 0.9998 - dense_3_accuracy: 0.9921 - dense_5_accuracy: 0.9948 - dense_7_accuracy: 0.9886 - dense_9_accuracy: 0.9876 - loss: 0.2932 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9006 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.8571 - val_loss: 1.3648\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - dense_1_accuracy: 0.9942 - dense_3_accuracy: 0.9905 - dense_5_accuracy: 0.9982 - dense_7_accuracy: 0.9926 - dense_9_accuracy: 0.9962 - loss: 0.2648 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9689 - val_dense_5_accuracy: 0.9317 - val_dense_7_accuracy: 0.8758 - val_dense_9_accuracy: 0.8385 - val_loss: 1.3473\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - dense_1_accuracy: 0.9920 - dense_3_accuracy: 0.9983 - dense_5_accuracy: 0.9953 - dense_7_accuracy: 0.9948 - dense_9_accuracy: 0.9900 - loss: 0.3051 - val_dense_1_accuracy: 1.0000 - val_dense_3_accuracy: 0.9565 - val_dense_5_accuracy: 0.9130 - val_dense_7_accuracy: 0.8696 - val_dense_9_accuracy: 0.8261 - val_loss: 1.4148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def makePredict(captcha):\n",
        "    captcha = np.reshape(captcha , (1, 50,200,1))\n",
        "    result = model_4.predict(captcha)\n",
        "    result = np.reshape(result ,(5,19))\n",
        "\n",
        "    label = ''.join([symbols[np.argmax(i)] for i in result])\n",
        "\n",
        "    return label\n",
        "def capcha_back(y, symbols = symbols):\n",
        "  label = ['','','','','']\n",
        "  for i in range(5):\n",
        "    for j in range(19):\n",
        "      if y[i][j] == 1:\n",
        "        label[i] = symbols[j]\n",
        "  return ''.join(label)\n",
        "\n",
        "print(symbols)\n",
        "count = 0\n",
        "for i in range(X_test.shape[0]):\n",
        "  pred = makePredict(X_test[i])\n",
        "  if pred != capcha_back(y_test[i]):\n",
        "    count+=1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLY0LNqBtUtK",
        "outputId": "f6126034-c74e-4959-d635-e69eb7ade9d1",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d', '7', 'n', '3', '4', '2', 'w', '6', 'f', '5', 'x', 'p', 'c', 'y', 'm', 'g', 'e', 'b', '8']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape[0], count, ((X_test.shape[0] - count) / X_test.shape[0] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM10q5VKBs1l",
        "outputId": "0a9c1316-478d-46e2-8b1f-109d5a1280aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160 23 85.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таким образом точность нашей модели на тестовой выборке составила 85.625 процентов, мне кажется точность могла улучшиться, если бы мы распологали большим количеством данных, хотя-бы в 2 раза."
      ],
      "metadata": {
        "id": "WaOAxZ1rGk0q"
      }
    }
  ]
}